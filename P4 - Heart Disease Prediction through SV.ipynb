{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dressed-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "# classifier models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# matplot libs\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt \n",
    "# to reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "# scoring\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
    "# to classification report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-benjamin",
   "metadata": {},
   "source": [
    "Abaixo, funcoes de plots (ou tentativas rs) de plotar o gráfico. O último que postei era essa primeira funcao. Este comentário será apagado em 24 horas, boa noite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "athletic-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dim_reduced_data(samples_2d, targets):\n",
    "    # tsne = TSNE(n_components=2, random_state=0) \n",
    "    # samples_2d = tsne.fit_transform(samples)\n",
    "    target_ids = range(2)\n",
    "    colors = 'r', 'g'\n",
    "    for i, c, label in zip(target_ids, colors, targets):\n",
    "        plt.scatter(samples_2d[targets == i, 0], samples_2d[targets == i, 1], c=c, label=label)\n",
    "    plt.grid(linestyle='--')\n",
    "    plt.legend(bbox_to_anchor=(1.15, 0.725, 0, 0))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hawaiian-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_val_scores(model, X_train, y_train, scoring=['f1_weighted','f1_macro','recall_weighted','precision_weighted'], \n",
    "                     cv=10):\n",
    "    _,__,f1_w,f1_m,r,p=cross_validate(model, X_train, y_train, cv=cv,\n",
    "                       scoring=scoring).items()\n",
    "    mean_f1_w = f1_w[1].mean(); sd_f1_w = f1_w[1].std()\n",
    "    mean_f1_m = f1_m[1].mean(); sd_f1_m = f1_m[1].std()\n",
    "    mean_r = r[1].mean(); sd_r = r[1].std()\n",
    "    mean_p = p[1].mean(); sd_p = p[1].std()\n",
    "    \n",
    "    print(\"Classification report for classifier {}:\\nparameters:\\n\".format(model) +\n",
    "          \"{}\\nmean: {}, std deviation: {}\\n\\n\".format(f1_w[0],mean_f1_w,sd_f1_w) +\n",
    "          \"{}\\nmean: {}, std deviation: {}\\n\\n\".format(f1_m[0],mean_f1_m,sd_f1_m) +\n",
    "          \"{}\\nmean: {}, std deviation: {}\\n\\n\".format(r[0],mean_r,sd_r) +\n",
    "          \"{}\\nmean: {}, std deviation: {}\\n\\n\".format(p[0],mean_p,sd_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "final-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_val_custom_score (model, X_train, y_train, \n",
    "                            scoring='f1_macro', \n",
    "                            cv=10):\n",
    "    print(\"Classification report for classifier {}:\\nparameters:\\n\".format(model))\n",
    "    \n",
    "    myReturn=cross_validate(model,X_train,y_train,cv=cv,scoring=scoring)\n",
    "    _,__,metric_score=myReturn\n",
    "    metric_score=myReturn[metric_score]\n",
    "    mean = np.mean(metric_score)\n",
    "    sd = np.std(metric_score)\n",
    "    print(\"{}\\nmean: {}, std deviation: {}\\n\\n\".format(scoring,mean,sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nutritional-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(clf, X, y, prediction):\n",
    "    print(f\"Classification report for classifier {clf}:\\n\"\n",
    "          f\"{metrics.classification_report(y, prediction)}\\n\")\n",
    "    disp = metrics.plot_confusion_matrix(clf, X, y)\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mathematical-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4133.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4185.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>4219.000000</td>\n",
       "      <td>4237.000000</td>\n",
       "      <td>3850.000000</td>\n",
       "      <td>4238.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429212</td>\n",
       "      <td>49.584946</td>\n",
       "      <td>1.978950</td>\n",
       "      <td>0.494101</td>\n",
       "      <td>9.003089</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.310524</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>236.721585</td>\n",
       "      <td>132.352407</td>\n",
       "      <td>82.893464</td>\n",
       "      <td>25.802008</td>\n",
       "      <td>75.878924</td>\n",
       "      <td>81.966753</td>\n",
       "      <td>0.151958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495022</td>\n",
       "      <td>8.572160</td>\n",
       "      <td>1.019791</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>11.920094</td>\n",
       "      <td>0.169584</td>\n",
       "      <td>0.076587</td>\n",
       "      <td>0.462763</td>\n",
       "      <td>0.158316</td>\n",
       "      <td>44.590334</td>\n",
       "      <td>22.038097</td>\n",
       "      <td>11.910850</td>\n",
       "      <td>4.080111</td>\n",
       "      <td>12.026596</td>\n",
       "      <td>23.959998</td>\n",
       "      <td>0.359023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>89.875000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              male          age    education  currentSmoker   cigsPerDay  \\\n",
       "count  4238.000000  4238.000000  4133.000000    4238.000000  4209.000000   \n",
       "mean      0.429212    49.584946     1.978950       0.494101     9.003089   \n",
       "std       0.495022     8.572160     1.019791       0.500024    11.920094   \n",
       "min       0.000000    32.000000     1.000000       0.000000     0.000000   \n",
       "25%       0.000000    42.000000     1.000000       0.000000     0.000000   \n",
       "50%       0.000000    49.000000     2.000000       0.000000     0.000000   \n",
       "75%       1.000000    56.000000     3.000000       1.000000    20.000000   \n",
       "max       1.000000    70.000000     4.000000       1.000000    70.000000   \n",
       "\n",
       "            BPMeds  prevalentStroke  prevalentHyp     diabetes      totChol  \\\n",
       "count  4185.000000      4238.000000   4238.000000  4238.000000  4188.000000   \n",
       "mean      0.029630         0.005899      0.310524     0.025720   236.721585   \n",
       "std       0.169584         0.076587      0.462763     0.158316    44.590334   \n",
       "min       0.000000         0.000000      0.000000     0.000000   107.000000   \n",
       "25%       0.000000         0.000000      0.000000     0.000000   206.000000   \n",
       "50%       0.000000         0.000000      0.000000     0.000000   234.000000   \n",
       "75%       0.000000         0.000000      1.000000     0.000000   263.000000   \n",
       "max       1.000000         1.000000      1.000000     1.000000   696.000000   \n",
       "\n",
       "             sysBP        diaBP          BMI    heartRate      glucose  \\\n",
       "count  4238.000000  4238.000000  4219.000000  4237.000000  3850.000000   \n",
       "mean    132.352407    82.893464    25.802008    75.878924    81.966753   \n",
       "std      22.038097    11.910850     4.080111    12.026596    23.959998   \n",
       "min      83.500000    48.000000    15.540000    44.000000    40.000000   \n",
       "25%     117.000000    75.000000    23.070000    68.000000    71.000000   \n",
       "50%     128.000000    82.000000    25.400000    75.000000    78.000000   \n",
       "75%     144.000000    89.875000    28.040000    83.000000    87.000000   \n",
       "max     295.000000   142.500000    56.800000   143.000000   394.000000   \n",
       "\n",
       "        TenYearCHD  \n",
       "count  4238.000000  \n",
       "mean      0.151958  \n",
       "std       0.359023  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('heart_pred.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-mattress",
   "metadata": {},
   "source": [
    "Retirando valores nulos e NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integrated-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2122.394967</td>\n",
       "      <td>0.443654</td>\n",
       "      <td>49.557440</td>\n",
       "      <td>1.979759</td>\n",
       "      <td>0.489059</td>\n",
       "      <td>9.022155</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.311543</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>236.873085</td>\n",
       "      <td>132.368025</td>\n",
       "      <td>82.912062</td>\n",
       "      <td>25.784185</td>\n",
       "      <td>75.730580</td>\n",
       "      <td>81.856127</td>\n",
       "      <td>0.152352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1230.175507</td>\n",
       "      <td>0.496883</td>\n",
       "      <td>8.561133</td>\n",
       "      <td>1.022657</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>11.918869</td>\n",
       "      <td>0.171602</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.463187</td>\n",
       "      <td>0.162335</td>\n",
       "      <td>44.096223</td>\n",
       "      <td>22.092444</td>\n",
       "      <td>11.974825</td>\n",
       "      <td>4.065913</td>\n",
       "      <td>11.982952</td>\n",
       "      <td>23.910128</td>\n",
       "      <td>0.359411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2139.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>25.380000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3199.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.250000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4237.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index         male          age    education  currentSmoker  \\\n",
       "count  3656.000000  3656.000000  3656.000000  3656.000000    3656.000000   \n",
       "mean   2122.394967     0.443654    49.557440     1.979759       0.489059   \n",
       "std    1230.175507     0.496883     8.561133     1.022657       0.499949   \n",
       "min       0.000000     0.000000    32.000000     1.000000       0.000000   \n",
       "25%    1050.750000     0.000000    42.000000     1.000000       0.000000   \n",
       "50%    2139.500000     0.000000    49.000000     2.000000       0.000000   \n",
       "75%    3199.250000     1.000000    56.000000     3.000000       1.000000   \n",
       "max    4237.000000     1.000000    70.000000     4.000000       1.000000   \n",
       "\n",
       "        cigsPerDay       BPMeds  prevalentStroke  prevalentHyp     diabetes  \\\n",
       "count  3656.000000  3656.000000      3656.000000   3656.000000  3656.000000   \n",
       "mean      9.022155     0.030361         0.005744      0.311543     0.027079   \n",
       "std      11.918869     0.171602         0.075581      0.463187     0.162335   \n",
       "min       0.000000     0.000000         0.000000      0.000000     0.000000   \n",
       "25%       0.000000     0.000000         0.000000      0.000000     0.000000   \n",
       "50%       0.000000     0.000000         0.000000      0.000000     0.000000   \n",
       "75%      20.000000     0.000000         0.000000      1.000000     0.000000   \n",
       "max      70.000000     1.000000         1.000000      1.000000     1.000000   \n",
       "\n",
       "           totChol        sysBP        diaBP          BMI    heartRate  \\\n",
       "count  3656.000000  3656.000000  3656.000000  3656.000000  3656.000000   \n",
       "mean    236.873085   132.368025    82.912062    25.784185    75.730580   \n",
       "std      44.096223    22.092444    11.974825     4.065913    11.982952   \n",
       "min     113.000000    83.500000    48.000000    15.540000    44.000000   \n",
       "25%     206.000000   117.000000    75.000000    23.080000    68.000000   \n",
       "50%     234.000000   128.000000    82.000000    25.380000    75.000000   \n",
       "75%     263.250000   144.000000    90.000000    28.040000    82.000000   \n",
       "max     600.000000   295.000000   142.500000    56.800000   143.000000   \n",
       "\n",
       "           glucose   TenYearCHD  \n",
       "count  3656.000000  3656.000000  \n",
       "mean     81.856127     0.152352  \n",
       "std      23.910128     0.359411  \n",
       "min      40.000000     0.000000  \n",
       "25%      71.000000     0.000000  \n",
       "50%      78.000000     0.000000  \n",
       "75%      87.000000     0.000000  \n",
       "max     394.000000     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "# data_columns=list(data.columns.values.tolist())\n",
    "data=data[data.notnull()]\n",
    "data=data.reset_index()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "olympic-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[\"TenYearCHD\"]\n",
    "X=data.drop('TenYearCHD',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efficient-racing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = TSNE(n_components=2).fit_transform(X)\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accomplished-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced=pca.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.20, random_state = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continent-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "active-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print data distribution after t-SNE reduction\n",
    "print_dim_reduced_data(X_train, y_train)\n",
    "# print_2d_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acceptable-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "major-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar grid para a Random Forest Classifier\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(5, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "grid_rfc = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 600, num = 6)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "documented-travel",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5e1ed06a115f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                n_iter = 30, cv = 10, random_state=200, scoring=f_beta)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_rfc = RandomForestClassifier()\n",
    "\n",
    "#  Random search of parameters. Uses our shuffle selection cross validation, \n",
    "#  and search across \"n_iter\" different (shuffle) combinations, and use all available cores\n",
    "rfc_search = RandomizedSearchCV(estimator = clf_rfc, param_distributions = grid_rfc, \n",
    "                               n_iter = 20, cv = 5, random_state=200, scoring=f_beta)\n",
    "\n",
    "rfc_search.fit(X_train, y_train)\n",
    "rfc_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aquatic-floor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457653466735238"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lesbian-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier RandomForestClassifier(max_depth=28, max_features='log2', min_samples_leaf=4,\n",
      "                       n_estimators=600):\n",
      "parameters:\n",
      "test_f1_weighted\n",
      "mean: 0.7848778807006177, std deviation: 0.0078026774934728035\n",
      "\n",
      "test_f1_macro\n",
      "mean: 0.49870089564478814, std deviation: 0.022206474956887334\n",
      "\n",
      "test_recall_weighted\n",
      "mean: 0.8437117209780729, std deviation: 0.004437338534083739\n",
      "\n",
      "test_precision_weighted\n",
      "mean: 0.7868553412534388, std deviation: 0.03482056789150965\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_grid_rfc = rfc_search.best_estimator_\n",
    "print_val_scores(best_grid_rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "instant-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier RandomForestClassifier(max_depth=28, max_features='log2', min_samples_leaf=4,\n",
      "                       n_estimators=600):\n",
      "parameters:\n",
      "\n",
      "0.07142857142857144\n",
      "mean: 0.050535926808141896, std deviation: 0.022393441165823962\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_val_custom_score(best_grid_rfc, X_train, y_train,f_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-reaction",
   "metadata": {},
   "source": [
    "SVM implementarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "likely-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None,\n",
      " 'standardscaler': StandardScaler(),\n",
      " 'standardscaler__copy': True,\n",
      " 'standardscaler__with_mean': True,\n",
      " 'standardscaler__with_std': True,\n",
      " 'steps': [('standardscaler', StandardScaler()), ('svc', SVC())],\n",
      " 'svc': SVC(),\n",
      " 'svc__C': 1.0,\n",
      " 'svc__break_ties': False,\n",
      " 'svc__cache_size': 200,\n",
      " 'svc__class_weight': None,\n",
      " 'svc__coef0': 0.0,\n",
      " 'svc__decision_function_shape': 'ovr',\n",
      " 'svc__degree': 3,\n",
      " 'svc__gamma': 'scale',\n",
      " 'svc__kernel': 'rbf',\n",
      " 'svc__max_iter': -1,\n",
      " 'svc__probability': False,\n",
      " 'svc__random_state': None,\n",
      " 'svc__shrinking': True,\n",
      " 'svc__tol': 0.001,\n",
      " 'svc__verbose': False,\n",
      " 'verbose': False}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clf_svm = make_pipeline(StandardScaler(), SVC())\n",
    "print(pprint(clf_svm.get_params() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-benjamin",
   "metadata": {},
   "source": [
    "É assim que se imprime os parâmetros de cada modelo. Agora, precisa treinar para os demais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "funky-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "C = [float(x) for x in np.linspace(start = 0.1, stop = 100.0, num = 10).astype(float)]\n",
    "class_weight=['balanced', None,{0:2,1:3},{0:5,1:1},{0:20,1:1},{0:200,1:3},{0:110,1:20}]\n",
    "kernel = ['linear', 'poly', 'rbf','sigmoid']\n",
    "gamma = ['scale', 'auto']\n",
    "decision_function_shape = ['ovo','ovr']\n",
    "shrinking = [True, False]\n",
    "\n",
    "grid_svm = {'svc__C': C,\n",
    "                   'svc__kernel': kernel,\n",
    "                   'svc__gamma': gamma,\n",
    "                   'svc__class_weight':class_weight,\n",
    "                   'svc__decision_function_shape': decision_function_shape,\n",
    "                   'svc__shrinking': shrinking}\n",
    "# pprint(grid_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search = RandomizedSearchCV(estimator = clf_svm, param_distributions = grid_svm, \n",
    "                               n_iter = 20, cv = 5, random_state=200, scoring=f_beta)\n",
    "\n",
    "svm_search.fit(X_train, y_train)\n",
    "svm_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "broadband-genius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=66.7, class_weight='balanced', kernel='linear'))]):\n",
      "parameters:\n",
      "\n",
      "make_scorer(fbeta_score, beta=3)\n",
      "mean: 0.4569187960633475, std deviation: 0.05632518415176265\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_clf_svm = svm_random.best_estimator_\n",
    "print_val_custom_score(best_clf_svm,X_train,y_train,f_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nuclear-mouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=66.7, class_weight='balanced', kernel='linear'))]):\n",
      "parameters:\n",
      "test_f1_weighted\n",
      "mean: 0.7258972122651761, std deviation: 0.02041769182436871\n",
      "\n",
      "test_f1_macro\n",
      "mean: 0.5669764493684443, std deviation: 0.025846950704187712\n",
      "\n",
      "test_recall_weighted\n",
      "mean: 0.6904939454859975, std deviation: 0.02475955695520791\n",
      "\n",
      "test_precision_weighted\n",
      "mean: 0.7885864255100286, std deviation: 0.01632103008099404\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_val_scores(best_clf_svm,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-divorce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-corner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-australia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dominant-hybrid",
   "metadata": {},
   "source": [
    "Abaixo, as funcoes sao apenas para demonstracao. Precisa primeiramente fazer cross-validation para encontrar os melhores hiperparâmetros, antes de fazer o teste final. As funcoes print_metrics e print_val_score auxiliam o print dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "natural-pencil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[627   4]\n",
      " [ 91  10]]\n",
      "\n",
      "\n",
      "Accuracy of Logistic Regression: 87.02185792349727 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       631\n",
      "           1       0.71      0.10      0.17       101\n",
      "\n",
      "    accuracy                           0.87       732\n",
      "   macro avg       0.79      0.55      0.55       732\n",
      "weighted avg       0.85      0.87      0.83       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m1 = 'Logistic Regression'\n",
    "lr = LogisticRegression()\n",
    "model = lr.fit(X_train, y_train)\n",
    "lr_predict = lr.predict(X_test)\n",
    "lr_conf_matrix = confusion_matrix(y_test, lr_predict)\n",
    "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
    "print(\"confussion matrix\")\n",
    "print(lr_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "surprised-press",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[595  36]\n",
      " [ 84  17]]\n",
      "\n",
      "\n",
      "Accuracy of Naive Bayes model: 83.60655737704919 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       631\n",
      "           1       0.32      0.17      0.22       101\n",
      "\n",
      "    accuracy                           0.84       732\n",
      "   macro avg       0.60      0.56      0.56       732\n",
      "weighted avg       0.80      0.84      0.81       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m2 = 'Naive Bayes'\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "nbpred = nb.predict(X_test)\n",
    "nb_conf_matrix = confusion_matrix(y_test, nbpred)\n",
    "nb_acc_score = accuracy_score(y_test, nbpred)\n",
    "print(\"confussion matrix\")\n",
    "print(nb_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Naive Bayes model:\",nb_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,nbpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "exposed-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[630   1]\n",
      " [ 97   4]]\n",
      "\n",
      "\n",
      "Accuracy of Random Forest: 86.6120218579235 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       631\n",
      "           1       0.80      0.04      0.08       101\n",
      "\n",
      "    accuracy                           0.87       732\n",
      "   macro avg       0.83      0.52      0.50       732\n",
      "weighted avg       0.86      0.87      0.81       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m3 = 'Random Forest Classfier'\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=12,max_depth=5)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_predicted = rf.predict(X_test)\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predicted)\n",
    "rf_acc_score = accuracy_score(y_test, rf_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "impressed-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[623   8]\n",
      " [ 93   8]]\n",
      "\n",
      "\n",
      "Accuracy of K-NeighborsClassifier: 86.20218579234972 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       631\n",
      "           1       0.50      0.08      0.14       101\n",
      "\n",
      "    accuracy                           0.86       732\n",
      "   macro avg       0.69      0.53      0.53       732\n",
      "weighted avg       0.82      0.86      0.82       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m5 = 'K-NeighborsClassifier'\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_predicted = knn.predict(X_test)\n",
    "knn_conf_matrix = confusion_matrix(y_test, knn_predicted)\n",
    "knn_acc_score = accuracy_score(y_test, knn_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(knn_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of K-NeighborsClassifier:\",knn_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sustained-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[618  13]\n",
      " [ 96   5]]\n",
      "\n",
      "\n",
      "Accuracy of DecisionTreeClassifier: 85.10928961748634 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       631\n",
      "           1       0.28      0.05      0.08       101\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.57      0.51      0.50       732\n",
      "weighted avg       0.78      0.85      0.80       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m6 = 'DecisionTreeClassifier'\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 6)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_predicted = dt.predict(X_test)\n",
    "dt_conf_matrix = confusion_matrix(y_test, dt_predicted)\n",
    "dt_acc_score = accuracy_score(y_test, dt_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(dt_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of DecisionTreeClassifier:\",dt_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,dt_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "republican-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix\n",
      "[[621  10]\n",
      " [ 97   4]]\n",
      "\n",
      "\n",
      "Accuracy of Support Vector Classifier: 85.38251366120218 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       631\n",
      "           1       0.29      0.04      0.07       101\n",
      "\n",
      "    accuracy                           0.85       732\n",
      "   macro avg       0.58      0.51      0.50       732\n",
      "weighted avg       0.78      0.85      0.80       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m7 = 'Support Vector Classifier'\n",
    "svc =  SVC(kernel='rbf', C=2)\n",
    "svc.fit(X_train, y_train)\n",
    "svc_predicted = svc.predict(X_test)\n",
    "svc_conf_matrix = confusion_matrix(y_test, svc_predicted)\n",
    "svc_acc_score = accuracy_score(y_test, svc_predicted)\n",
    "print(\"confussion matrix\")\n",
    "print(svc_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Support Vector Classifier:\",svc_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,svc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-summary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
